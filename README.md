# ğŸš€ Pipeline de Dados em AWS

Este projeto cria um pipeline simples de dados utilizando serviÃ§os serverless da AWS para processar arquivos CSV de transaÃ§Ãµes e enriquecÃª-los com informaÃ§Ãµes de paÃ­ses.  
O objetivo Ã© gerar uma tabela final pronta para anÃ¡lises usando Amazon Athena.

---

# ğŸ“ Arquitetura do Projeto

O pipeline Ã© composto por:

1. **S3 â€“ Data Lake (Bronze e Gold)**
2. **Glue Job â€“ Limpeza, Enriquecimento e Processamento**
3. **Athena â€“ Tabela Final e Consultas**

A seguir estÃ¡ uma explicaÃ§Ã£o simples e direta de cada componente.

---

# ğŸª£ 1. S3 â€“ OrganizaÃ§Ã£o do Data Lake

O bucket do projeto Ã©:

```
solagoralmb
```

Estrutura utilizada:

```
solagoralmb/
  â”œâ”€ bronze/
  â”‚    â”œâ”€ countries/
  â”‚    â”‚     â””â”€ countries.csv
  â”‚    â””â”€ transactions/
  â”‚          â””â”€ transactions_*.csv
  â”‚
  â””â”€ gold/
       â””â”€ transactions_country/
```

### â€¢ Bronze  
Armazena os arquivos CSV brutos exatamente como foram recebidos.

### â€¢ Gold  
Armazena os dados jÃ¡ tratados, enriquecidos e convertidos para **Parquet**, prontos para uso no Athena.

---

# ğŸš€ 2. Glue Job â€“ ETL (PySpark)

O Glue Job Ã© responsÃ¡vel por:

- Ler os CSV brutos da camada Bronze
- Tratar tipos (datas, nÃºmeros)
- Enriquecer os dados com a tabela de paÃ­ses
- Calcular:
  - `days_delay`
  - `is_late`
- Escrever o resultado final na camada Gold, em Parquet

Script utilizado no Glue:

```
src/glue/transactions_etl.py
```

A saÃ­da do job Ã© gravada em:

```
s3://solagoralmb/gold/transactions_country/
```

---

# ğŸ“Š 3. Athena â€“ Tabela Final

ApÃ³s o Glue Job gerar os arquivos Parquet, criamos a tabela no Athena:

```sql
CREATE DATABASE IF NOT EXISTS finance;

CREATE EXTERNAL TABLE IF NOT EXISTS finance.transactions_country (
  transaction_id        string,
  country_code          string,
 country               string,
  transaction_date      date,
  bank                  string,
  company               string,
  transaction_value     double,
  payment_due_date      date,
  days_delay            int,
  is_late               boolean
)
PARTITIONED BY (
  ingestion_date string
)
STORED AS PARQUET
LOCATION 's3://solagoralmb/gold/transactions_country/';
```

Atualizar as partiÃ§Ãµes:

```sql
MSCK REPAIR TABLE finance.transactions_country;
```

---

# ğŸ“ˆ Consultas de NegÃ³cio (Athena)

### PaÃ­ses com mais transaÃ§Ãµes
```sql
SELECT country, COUNT(*) AS total
FROM finance.transactions_country
GROUP BY country
ORDER BY total DESC;
```

### Bancos com mais transaÃ§Ãµes
```sql
SELECT bank, COUNT(*) AS total
FROM finance.transactions_country
GROUP BY bank
ORDER BY total DESC;
```

### Datas com maior volume
```sql
SELECT transaction_date, COUNT(*) AS total
FROM finance.transactions_country
GROUP BY transaction_date
ORDER BY total DESC;
```

### TransaÃ§Ãµes mais atrasadas
```sql
SELECT *
FROM finance.transactions_country
WHERE is_late = true
ORDER BY days_delay DESC
LIMIT 50;
```

---

# ğŸ“¦ Estrutura do RepositÃ³rio

```
.
â”œâ”€â”€ README.md
â”‚
â”œâ”€â”€ src/
â”‚    â””â”€â”€ glue/
â”‚          â””â”€â”€ transactions_etl.py
â”‚
â””â”€â”€ athena/
     â”œâ”€â”€ create_table.sql
     â””â”€â”€ queries.sql
```

---

# ğŸ› ï¸ Como Executar

1. Suba os CSV de paÃ­ses e transaÃ§Ãµes para o S3 na pasta **bronze/**
2. Rode o Glue Job usando o script `transactions_etl.py`
3. Verifique se os Parquets foram gerados na pasta **gold/**
4. Crie a tabela no Athena
5. Execute as consultas de negÃ³cio

---

# ğŸ¯ Resultado Final

No fim, o pipeline entrega:

- Dados brutos armazenados no S3 (Bronze)
- Dados tratados e enriquecidos em Parquet (Gold)
- Tabela final no Athena pronta para consultas
- SQLs para anÃ¡lise de paÃ­ses, bancos, datas e atrasos

Pipeline simples, direto ao ponto e funcional usando componentes totalmente serverless da AWS.
